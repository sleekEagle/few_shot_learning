{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUTWNETE data\\n\\nwalk    11111  0\\nstand   11112  1 \\njog     11113  2\\nsit     11114  3\\nbike    11115  4\\nupstairs 11116  5\\ndownstairs 11117  6\\ntype    11118  7\\nwrite   11119  8\\ncoffee  11120  9\\ntalk    11121  10\\nsmoke   11122  11\\neat     11123  12\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch import optim as optim\n",
    "import torch.autograd as autograd\n",
    "import importlib\n",
    "import Extract_data\n",
    "importlib.reload(Extract_data)\n",
    "import Inference\n",
    "importlib.reload(Inference)\n",
    "import matplotlib.pyplot as plt\n",
    "import CenterLoss as cl\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import Model\n",
    "importlib.reload(Model)\n",
    "import sys\n",
    "\n",
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "#n is the number of times the data is iterated repeatedly to extract data\n",
    "def get_data(data,n_times):\n",
    "    chunks,labels,_=Extract_data.get_batch(data,bs=len(data),sr=sr,segment_len=segment_len,step=step)\n",
    "    for i in range(n):\n",
    "        c,l,_=Extract_data.get_batch(data,bs=len(data),sr=sr,segment_len=segment_len,step=step)\n",
    "        chunks=chunks.append(c)\n",
    "        labels=np.append(labels,l,axis=0)\n",
    "    return chunks,labels\n",
    "\n",
    "def get_acc(model,data):\n",
    "    comb_model.eval()\n",
    "    chunks,labels=get_data(data,n_times=5)\n",
    "    correct_num=0\n",
    "    for i in range(len(chunks)):\n",
    "        d=torch.from_numpy(chunks.iloc[i])\n",
    "        d=torch.unsqueeze(d,dim=0).float()\n",
    "        d=d.to(device)\n",
    "        l=torch.from_numpy(labels)\n",
    "        l=l.to(device)\n",
    "        l=l[i].view(1).item()\n",
    "        #print(l)\n",
    "        pred=model(d)\n",
    "        predmax=torch.max(pred,1).indices.item()\n",
    "        #print(predmax)\n",
    "        #print('_____')\n",
    "        if(predmax==l):\n",
    "            correct_num+=1\n",
    "    comb_model.train()\n",
    "    return correct_num/len(data)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "UCI data labels\n",
    "0 WALKING           \n",
    "1 WALKING_UPSTAIRS  \n",
    "2 WALKING_DOWNSTAIRS\n",
    "3 SITTING           \n",
    "4 STANDING          \n",
    "5 LAYING            \n",
    "6 STAND_TO_SIT      \n",
    "7 SIT_TO_STAND      \n",
    "8 SIT_TO_LIE        \n",
    "9 LIE_TO_SIT        \n",
    "10 STAND_TO_LIE      \n",
    "11 LIE_TO_STAND \n",
    "'''\n",
    "\n",
    "'''\n",
    "UTWNETE data\n",
    "\n",
    "walk    11111  0\n",
    "stand   11112  1 \n",
    "jog     11113  2\n",
    "sit     11114  3\n",
    "bike    11115  4\n",
    "upstairs 11116  5\n",
    "downstairs 11117  6\n",
    "type    11118  7\n",
    "write   11119  8\n",
    "coffee  11120  9\n",
    "talk    11121  10\n",
    "smoke   11122  11\n",
    "eat     11123  12\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from UTWNETE\n",
    "data_df=Extract_data.get_UTWNETE_data()\n",
    "activities={\n",
    "    0:'walk',\n",
    "    1:'stand',\n",
    "    2:'jog',\n",
    "    3:'sit',\n",
    "    4:'bike',\n",
    "    5:'upstairs',\n",
    "    6:'downstairs',\n",
    "    7:'type',\n",
    "    8:'write',\n",
    "    9:'drink',\n",
    "    10:'talk',\n",
    "    11:'smoke',\n",
    "    12:'eat'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lnw8px/models/HAR_research/center_loss/Extract_data.py:280: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected['diff']=diffs\n"
     ]
    }
   ],
   "source": [
    "#load data from PAMAP2 dataset\n",
    "data_df=Extract_data.get_PAMAP2_Data()\n",
    "#interpolate NAN values\n",
    "k=data_df['data'].apply(Extract_data.interpolate)\n",
    "\n",
    "participants=np.unique(data_df['participant'])\n",
    "groups=[participants[:3],participants[3:6],participants[6:]]\n",
    "\n",
    "'''\n",
    "#scaled to -1 +1\n",
    "min_val,max_val=np.min(pred_df.apply(np.min,axis=0).values),np.max(pred_df.apply(np.max,axis=0).values)\n",
    "scaled=pred_df.apply(get_global_standardized,args=[np.array([max_val]),np.array([min_val])],axis=1)\n",
    "print(np.max(scaled.apply(np.max,axis=1)),np.min(scaled.apply(np.min,axis=1)))\n",
    "pred_df=scaled\n",
    "'''\n",
    "\n",
    "activities={\n",
    "    0:'other',\n",
    "    1:'lying',\n",
    "    2:'sitting',\n",
    "    3:'standing',\n",
    "    4:'walking',\n",
    "    5:'running',\n",
    "    6:'cycling',\n",
    "    7:'Nordic walking',\n",
    "    9:'watching TV',\n",
    "    10:'computer work',\n",
    "    11:'car driving',\n",
    "    12:'ascending stairs',\n",
    "    13:'descending stairs',\n",
    "    16:'vacuum cleaning',\n",
    "    17:'ironing',\n",
    "    18:'folding laundry',\n",
    "    19:'house cleaning',\n",
    "    20:'playing soccer',\n",
    "    24:'rope jumping'  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_name(label,activities):\n",
    "    return activities[label]\n",
    "data_df['activity_name']=data_df['label'].apply(get_activity_name,args=[activities])\n",
    "data_df['activity_vec']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class divisions mentioned in paper\n",
    "Few-Shot Learning-Based Human Activity Recognition by\n",
    "Feng and Duarte\n",
    "'''\n",
    "seen_classes=['lying','standing','walking','running','ascending stairs','vacuum cleaning','rope jumping']\n",
    "unseen_classes=['sitting','cycling','Nordic walking','descending stairs','ironing']\n",
    "\n",
    "def get_Feng_seen_unseen(seen_group,unseen_group):\n",
    "    seen_df=data_df[data_df['participant'].isin(seen_group)]\n",
    "    unseen_df=data_df[data_df['participant'].isin(unseen_group)]\n",
    "\n",
    "    seen_data=seen_df[seen_df['activity_name'].isin(seen_classes)]\n",
    "    unseen_data=unseen_df[unseen_df['activity_name'].isin(unseen_classes)]\n",
    "\n",
    "    seen_data['label']=Extract_data.get_remapped_labels(seen_data)\n",
    "    unseen_data['label']=Extract_data.get_remapped_labels(unseen_data)\n",
    "    \n",
    "    return seen_data,unseen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seen_unseen_data(num_unseen_classes):\n",
    "    keys=list(activities.keys())\n",
    "    random.shuffle(keys)\n",
    "    unseen_classes=keys[0:num_unseen_classes]\n",
    "    seen_classes=keys[num_unseen_classes:]\n",
    "    seen_data=data_df[data_df['label'].isin(seen_classes)]\n",
    "    unseen_data=data_df[data_df['label'].isin(unseen_classes)]\n",
    "\n",
    "    seen_data['label']=Extract_data.get_remapped_labels(seen_data)\n",
    "    unseen_data['label']=Extract_data.get_remapped_labels(unseen_data)\n",
    "\n",
    "    return seen_data,unseen_data,unseen_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['data'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,labels,activity_name,_=Extract_data.get_n_times_cropped_data(train_df,bs=len(train_df),n_times=20,\n",
    "                                                                    sr=sr,\n",
    "                                                                    segment_len_s=segment_len_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelWork.model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "feature_dim=1664\n",
      "cuda\n",
      "feature_dim=1664\n",
      "cuda\n",
      "feature_dim=1664\n",
      "(<class 'KeyboardInterrupt'>, KeyboardInterrupt(), <traceback object at 0x7f55e44d2230>)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b51ecc71eaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0;31m#knn_accuracy,pred,test_labels=Inference.train_KNN(knn_train_df,knn_test_df,n_neighbors=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                     \u001b[0mtotal_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mper_class_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_similarity_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_train_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_test_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                     \u001b[0;31m#df=pd.DataFrame()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/models/HAR_research/center_loss/Inference.py\u001b[0m in \u001b[0;36mtrain_similarity_classifier\u001b[0;34m(train_df, test_df)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_closest_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0mtotal_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mper_class_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4044\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4045\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   4030\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4031\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/models/HAR_research/center_loss/Inference.py\u001b[0m in \u001b[0;36mget_closest_class\u001b[0;34m(row, centroids)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dist'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_euclidian_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mmin_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmin_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2985\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3039\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3601\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5252\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5240\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5241\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5249\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \"\"\"\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mis_consolidated\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-b51ecc71eaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0;31m#print(acc_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/lnw8px/models/HAR_research/tune_embedding/tune_exceptions.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0mDRAFT\u001b[0m \u001b[0msupport\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrouting_id\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \"\"\"\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mrouting_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 data = zmq.Frame(data, track=track, copy=copy or None,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LAMBDA=0.0005\n",
    "segment_len_s=10\n",
    "sr=100\n",
    "discount=0.8\n",
    "bs=4\n",
    "num_embeddings=128\n",
    "for num_kernels in [64,128,256]:\n",
    "    for num_unseen_classes in range(2,10):\n",
    "        for k in range(20):\n",
    "            seen_data,unseen_data,unseen_classes=get_seen_unseen_data(num_unseen_classes)\n",
    "            try:\n",
    "                train_df,test_df=Extract_data.divide_data(seen_data,ratio=0.9)\n",
    "                #initialize model\n",
    "                modelWork=Model.ModelWork(len(np.unique(train_df['activity_name'])),num_embeddings,\n",
    "                                         in_channels=18,\n",
    "                                         sr=sr,\n",
    "                                         segment_len_s=segment_len_s,\n",
    "                                         num_kernels=num_kernels)\n",
    "                max_acc,train_loss_list,train_word_loss_list,train_center_loss_list=modelWork.train(train_df,test_df,LAMBDA=LAMBDA,\n",
    "                                                                                                    ALPHA=0,\n",
    "                                                                                                    max_itr=10000,\n",
    "                                                                                                    discount=discount,\n",
    "                                                                                                    bs=bs)\n",
    "                data,labels,activity_name,_=Extract_data.get_n_times_cropped_data(unseen_data,bs=len(unseen_data),n_times=20,\n",
    "                                                                               sr=sr,\n",
    "                                                                               segment_len_s=segment_len_s)\n",
    "                data=data.to(device)\n",
    "                embedding,pred=modelWork.model(data)\n",
    "                embedding=embedding.detach().cpu().numpy()\n",
    "                d=pd.DataFrame()\n",
    "                d['data']=[f for f in embedding]\n",
    "                d['activity_name']=activity_name.values\n",
    "\n",
    "                d=d.rename(columns={'activity_name':'label'})\n",
    "                d['label_num']=Extract_data.get_remapped_labels(d)\n",
    "                d=d.rename(columns={'label_num':'label','label':'activity_name'})\n",
    "                for num_samples in range(1,6):\n",
    "                    towrite=''\n",
    "                    towrite+=(str(num_kernels)+';'+str(num_unseen_classes)+';'+str(max_acc))\n",
    "                    #f.write(str(LAMBDA)+';'+str(ALPHA)+';'+str(num_embeddings))\n",
    "                    #f.write(';'+str(max_acc))\n",
    "                    eval_train_df,eval_test_df=Inference.divide_data(d,num_samples=num_samples)\n",
    "                    towrite+=(';'+str(num_samples))\n",
    "                    #f.write(';'+str(num_samples))\n",
    "                    #knn_accuracy,pred,test_labels=Inference.train_KNN(knn_train_df,knn_test_df,n_neighbors=1)\n",
    "                    total_acc,per_class_acc=Inference.train_similarity_classifier(eval_train_df,eval_test_df)\n",
    "                    #df=pd.DataFrame()\n",
    "                    #df['test_labels']=test_labels\n",
    "                    #df['iscorrect']=pred==test_labels\n",
    "                    #df.groupby(['test_labels']).mean()\n",
    "                    towrite+=(';'+str(total_acc)+';'+str(per_class_acc['iscorrect'].values)+ '\\n')\n",
    "                    towrite=towrite.replace('\\n', '')\n",
    "                    towrite+='*\\n'\n",
    "                    #f.write(';'+str(str(df.groupby(['test_labels']).mean()['iscorrect'].values)))\n",
    "                    #f.write(';'+str(acc_list[0]))\n",
    "                    #f.write(';'+str(unseen_classes)+ '\\n')\n",
    "                    f = open(\"/home/lnw8px/models/HAR_research/center_loss/see.txt\", \"a\")\n",
    "                    f.write(towrite)\n",
    "                    f.close()\n",
    "                    #print(acc_list)\n",
    "            except:\n",
    "                print(sys.exc_info())\n",
    "                f = open(\"/home/lnw8px/models/HAR_research/tune_embedding/tune_exceptions.txt\", \"a\")\n",
    "                f.write(str(sys.exc_info())+'\\n')\n",
    "                f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lnw8px/.local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/home/lnw8px/.local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lnw8px/.local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/home/lnw8px/.local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lnw8px/.local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/home/lnw8px/.local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lnw8px/.local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/home/lnw8px/.local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lnw8px/.local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/home/lnw8px/.local/lib/python3.7/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "LAMBDA=0.00005\n",
    "ALPHA=0.5\n",
    "num_embeddings=256\n",
    "for num_unseen_classes in [3,4,5,6]:\n",
    "    for i in range(80):\n",
    "        try:\n",
    "            seen_data,unseen_data,unseen_classes=get_seen_unseen_data(num_unseen_classes=num_unseen_classes)\n",
    "            train_df,test_df=Extract_data.divide_data(seen_data,ratio=0.9)\n",
    "            #initialize model\n",
    "            modelWork=Model.ModelWork(len(np.unique(train_df['activity_name'])),num_embeddings)\n",
    "            max_acc,train_loss_list,train_word_loss_list,train_center_loss_list=modelWork.train(train_df,test_df,LAMBDA=LAMBDA,max_itr=2000)\n",
    "            data,labels,activity_name=Extract_data.get_n_times_cropped_data(unseen_data,bs=len(unseen_data),n_times=2)\n",
    "            data=data.to(device)\n",
    "            embedding,pred=modelWork.model(data)\n",
    "            embedding=embedding.detach().cpu().numpy()\n",
    "            d=pd.DataFrame()\n",
    "            d['data']=[f for f in embedding]\n",
    "            d['activity_name']=activity_name.values\n",
    "\n",
    "            d=d.rename(columns={'activity_name':'label'})\n",
    "            d['label_num']=Extract_data.get_remapped_labels(d)\n",
    "            d=d.rename(columns={'label_num':'label','label':'activity_name'})\n",
    "            towrite=''\n",
    "            for num_samples in range(1,3):\n",
    "                f = open(\"/home/lnw8px/models/HAR_research/tune_embedding/different_unseen_classes.txt\", \"a\")\n",
    "                towrite+=(str(LAMBDA)+';'+str(ALPHA)+';'+str(num_embeddings)+';'+str(max_acc))\n",
    "                #f.write(str(LAMBDA)+';'+str(ALPHA)+';'+str(num_embeddings))\n",
    "                #f.write(';'+str(max_acc))\n",
    "\n",
    "                knn_train_df,knn_test_df=Inference.divide_data(d,num_samples=num_samples)\n",
    "                towrite+=(';'+str(num_samples))\n",
    "                #f.write(';'+str(num_samples))\n",
    "                knn_accuracy,pred,test_labels=Inference.train_KNN(knn_train_df,knn_test_df,n_neighbors=1)\n",
    "\n",
    "                df=pd.DataFrame()\n",
    "                df['test_labels']=test_labels\n",
    "                df['iscorrect']=pred==test_labels\n",
    "                #df.groupby(['test_labels']).mean()\n",
    "                towrite+=(';'+str(str(df.groupby(['test_labels']).mean()['iscorrect'].values))+';'+str(knn_accuracy)+';'+str(unseen_classes)+ '\\n')\n",
    "                #f.write(';'+str(str(df.groupby(['test_labels']).mean()['iscorrect'].values)))\n",
    "                #f.write(';'+str(acc_list[0]))\n",
    "                #f.write(';'+str(unseen_classes)+ '\\n')\n",
    "                f.write(towrite)\n",
    "                f.close()\n",
    "                #print(acc_list)\n",
    "        except:\n",
    "            print(sys.exc_info())\n",
    "            f = open(\"/home/lnw8px/models/HAR_research/tune_embedding/tune_exceptions.txt\", \"a\")\n",
    "            f.write(str(sys.exc_info())+'\\n')\n",
    "            f.close()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.5.1 Py3.7",
   "language": "python",
   "name": "pytorch-1.5.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
